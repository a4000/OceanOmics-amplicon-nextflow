manifest {
    author = 'Adam Bennett'
    name = 'OceanOmics-Amplicon-Nextflow' 
    description = 'This is the nextflow version of the OceanOmics amplicon pipeline using Docker containers'
    mainScript = 'main.nf'
    version = '0.0.1'
}

resume = true

// The parameters for the pipeline
// These can be set at the command line, or set here in the config file
params {
    ////////////////////////////////////////////////////////////
    // Parameters to skip steps
    ////////////////////////////////////////////////////////////

    skip_demux = true
    skip_lulu = false

    
    ////////////////////////////////////////////////////////////
    // Mandatory parameters
    ////////////////////////////////////////////////////////////

    project_id = "RSV5"
    assay = "16S,MiFish"                // Please separate multiple assays with commas (e.g., "16S,MiFish")
    metadata_file = "RSV5_metadata.csv" // .csv file with 'Sample ID' column
    scripts_dir = "scripts"
    resources_dir = "resources"
    

    ////////////////////////////////////////////////////////////
    // Mandatory parameters if using the --skip_demux option
    ////////////////////////////////////////////////////////////

    demux_dir = "demux_files"           // The directory containing the demultiplexed files (with extensions _${assay}.[12].fq.gz)


    ////////////////////////////////////////////////////////////
    // Mandatory files if not using the --skip_demux option
    ////////////////////////////////////////////////////////////

    // These files should be in the same directory as main.nf and nextflow.config
    // These files can't be symbolic links

    // - Fw index file with the name "${project_id}_${assay}_Fw.fa" (e.g., ABV4_16S_Fw.fa)
    // - Rv index file with the name "${project_id}_${assay}_Rv.fa" (e.g., ABV4_16S_Rv.fa)
    // - Sample rename pattern file with the name "Sample_name_rename_pattern_${project_id}_${assay}.txt" (e.g., Sample_name_rename_pattern_ABV4_16S.txt)
    // - Raw data R1 with the name "*${assay}*R1*fastq.gz" (e.g., AbrolhosV4_MiFish_Fish16S_S1_R1_001.fastq.gz)
    // - Raw data R2 with the name "*${assay}*R2*fastq.gz" (e.g., AbrolhosV4_MiFish_Fish16S_S1_R2_001.fastq.gz)


    ////////////////////////////////////////////////////////////
    // Optional parameters
    ////////////////////////////////////////////////////////////

    sequencing_run_id = ""              // Can be left as an empty string
    cores = 25                          // The max number of cores used will be 'cores' * number of assays
    publish_dir_mode = "symlink"        // Different publishing mode options can be viewed at https://www.nextflow.io/docs/latest/process.html#publishdir
    publish_dir_mode_final = "move"     // This is the publishing mode of the final process
    database_option = "ocom"            // database_option can be "nt", "ocom", or "custom"; only ocom has been tested so far
    dada_option = "FALSE"               // dada_option can be "TRUE", "FALSE", or "pseudo" for the pool setting
    merge_pairs_min_overlap = 12        // The min overlap required for merging reads
    merge_pairs_max_mismatch = 0        // The max mismatches allowed in overlap region
    optimise_tree = false               // Optimise the phylogenetic tree in the phyloseq object (Warning: this option can be very slow)
    control_grep_patterns = "WC,FC,EB"  // comma separated list of Control patterns (e.g., "WC,FC,EB")
    trim_side = "Left"                  // Trim on the "Left" or "Right" side of the reads
    trim_R1 = 20                        // length to trim from read 1 (this currently isn't working because different assays might have different trim lengths)
    trim_R2 = 22                        // length to trim from read 2 (this currently isn't working because different assays might have different trim lengths)
    single_end = false                  // use this option if your data is single end
}


process {
    container = 'sebrauschert/amplicon_pipeline:v0.3'
    cpus = { 64 * task.attempt }
    memory = { 128.GB * task.attempt }
    time = { 100.h * task.attempt }
}


docker {
    enabled = true
    runOptions = '-v $PWD:/mnt/scratch -u \$(id -u $USER):\$(id -g $USER)'
}